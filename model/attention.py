import torch.nn as nn



class RMSNorm(nn.Module):
    def __init__(self, config):
        super().__init__()
    
    def forward(self, x):
        out = x
        return out
    

class GQAttention(nn.Module):
    def __init__(self, config):
        super().__init__()

    
    def _init_tensor(self):
        return

    def forward(self, x):
        out = x
        return out
    